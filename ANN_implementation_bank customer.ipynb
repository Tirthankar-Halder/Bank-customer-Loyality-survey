{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Processing\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data filtration\n",
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the Data Frames\n",
    "##as the both data is categorial data\n",
    "X=pd.concat([X,geography,gender],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Unnecessary columns\n",
    "#already convert in previous\n",
    "X=X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "0                  1        101348.88        0      0     0  \n",
       "1                  1        112542.58        0      1     0  \n",
       "2                  0        113931.57        0      0     0  \n",
       "3                  0         93826.63        0      0     0  \n",
       "4                  1         79084.10        0      1     0  \n",
       "...              ...              ...      ...    ...   ...  \n",
       "9995               0         96270.64        0      0     1  \n",
       "9996               1        101699.77        0      0     1  \n",
       "9997               1         42085.58        0      0     0  \n",
       "9998               0         92888.52        1      0     1  \n",
       "9999               0         38190.78        0      0     0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "##for w*x processs will be faster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units= 6,kernel_initializer = 'he_uniform',activation='relu',input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout\n",
    "#clasiifier.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6,kernel_initializer= 'he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout\n",
    "#clasiifier.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1,kernel_initializer= 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "#I have used adam optimiser as it is very much populer and most used optimiser\n",
    "classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 3s 3ms/step - loss: 1.0535 - accuracy: 0.4341 - val_loss: 0.5171 - val_accuracy: 0.7910\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 0s 930us/step - loss: 0.4983 - accuracy: 0.7980 - val_loss: 0.4719 - val_accuracy: 0.8012\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 0s 910us/step - loss: 0.4481 - accuracy: 0.8079 - val_loss: 0.4440 - val_accuracy: 0.8122\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 0s 919us/step - loss: 0.4135 - accuracy: 0.8265 - val_loss: 0.4240 - val_accuracy: 0.8167\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 0s 930us/step - loss: 0.4116 - accuracy: 0.8244 - val_loss: 0.4080 - val_accuracy: 0.8281\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 944us/step - loss: 0.3798 - accuracy: 0.8458 - val_loss: 0.3945 - val_accuracy: 0.8368\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 0s 926us/step - loss: 0.3722 - accuracy: 0.8474 - val_loss: 0.3852 - val_accuracy: 0.8398\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 960us/step - loss: 0.3620 - accuracy: 0.8510 - val_loss: 0.3781 - val_accuracy: 0.8395\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 981us/step - loss: 0.3632 - accuracy: 0.8552 - val_loss: 0.3735 - val_accuracy: 0.8410\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 0s 918us/step - loss: 0.3575 - accuracy: 0.8518 - val_loss: 0.3699 - val_accuracy: 0.8444\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 949us/step - loss: 0.3575 - accuracy: 0.8509 - val_loss: 0.3683 - val_accuracy: 0.8436\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 970us/step - loss: 0.3492 - accuracy: 0.8557 - val_loss: 0.3660 - val_accuracy: 0.8440\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 972us/step - loss: 0.3323 - accuracy: 0.8629 - val_loss: 0.3641 - val_accuracy: 0.8429\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 992us/step - loss: 0.3546 - accuracy: 0.8535 - val_loss: 0.3648 - val_accuracy: 0.8451\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3391 - accuracy: 0.8580 - val_loss: 0.3631 - val_accuracy: 0.8493\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 938us/step - loss: 0.3404 - accuracy: 0.8618 - val_loss: 0.3628 - val_accuracy: 0.8489\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 954us/step - loss: 0.3362 - accuracy: 0.8615 - val_loss: 0.3619 - val_accuracy: 0.8470\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 0s 932us/step - loss: 0.3344 - accuracy: 0.8626 - val_loss: 0.3621 - val_accuracy: 0.8489\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 971us/step - loss: 0.3548 - accuracy: 0.8531 - val_loss: 0.3620 - val_accuracy: 0.8474\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 1s 949us/step - loss: 0.3490 - accuracy: 0.8503 - val_loss: 0.3621 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 955us/step - loss: 0.3363 - accuracy: 0.8626 - val_loss: 0.3617 - val_accuracy: 0.8470\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 1s 937us/step - loss: 0.3478 - accuracy: 0.8586 - val_loss: 0.3609 - val_accuracy: 0.8478\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 0s 932us/step - loss: 0.3310 - accuracy: 0.8668 - val_loss: 0.3608 - val_accuracy: 0.8501\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 946us/step - loss: 0.3250 - accuracy: 0.8653 - val_loss: 0.3617 - val_accuracy: 0.8478\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 976us/step - loss: 0.3256 - accuracy: 0.8645 - val_loss: 0.3611 - val_accuracy: 0.8485\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 943us/step - loss: 0.3438 - accuracy: 0.8527 - val_loss: 0.3620 - val_accuracy: 0.8474\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 0s 931us/step - loss: 0.3241 - accuracy: 0.8671 - val_loss: 0.3610 - val_accuracy: 0.8489\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 986us/step - loss: 0.3293 - accuracy: 0.8652 - val_loss: 0.3625 - val_accuracy: 0.8482\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 1s 980us/step - loss: 0.3260 - accuracy: 0.8659 - val_loss: 0.3605 - val_accuracy: 0.8485\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 971us/step - loss: 0.3303 - accuracy: 0.8666 - val_loss: 0.3612 - val_accuracy: 0.8474\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 951us/step - loss: 0.3247 - accuracy: 0.8673 - val_loss: 0.3612 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 965us/step - loss: 0.3354 - accuracy: 0.8627 - val_loss: 0.3610 - val_accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 972us/step - loss: 0.3238 - accuracy: 0.8652 - val_loss: 0.3604 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 935us/step - loss: 0.3249 - accuracy: 0.8636 - val_loss: 0.3612 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 0s 929us/step - loss: 0.3330 - accuracy: 0.8595 - val_loss: 0.3617 - val_accuracy: 0.8489\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 0s 919us/step - loss: 0.3291 - accuracy: 0.8640 - val_loss: 0.3603 - val_accuracy: 0.8497\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 0s 932us/step - loss: 0.3362 - accuracy: 0.8621 - val_loss: 0.3597 - val_accuracy: 0.8501\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 960us/step - loss: 0.3374 - accuracy: 0.8585 - val_loss: 0.3609 - val_accuracy: 0.8516\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 966us/step - loss: 0.3255 - accuracy: 0.8672 - val_loss: 0.3591 - val_accuracy: 0.8504\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 975us/step - loss: 0.3245 - accuracy: 0.8655 - val_loss: 0.3594 - val_accuracy: 0.8519\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 0s 925us/step - loss: 0.3386 - accuracy: 0.8559 - val_loss: 0.3590 - val_accuracy: 0.8531\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 948us/step - loss: 0.3229 - accuracy: 0.8654 - val_loss: 0.3592 - val_accuracy: 0.8523\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 955us/step - loss: 0.3244 - accuracy: 0.8657 - val_loss: 0.3583 - val_accuracy: 0.8519\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 1s 969us/step - loss: 0.3158 - accuracy: 0.8716 - val_loss: 0.3590 - val_accuracy: 0.8519\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 1s 980us/step - loss: 0.3427 - accuracy: 0.8574 - val_loss: 0.3589 - val_accuracy: 0.8504\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3356 - accuracy: 0.8602 - val_loss: 0.3591 - val_accuracy: 0.8497\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 948us/step - loss: 0.3283 - accuracy: 0.8653 - val_loss: 0.3591 - val_accuracy: 0.8538\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 1s 996us/step - loss: 0.3459 - accuracy: 0.8521 - val_loss: 0.3582 - val_accuracy: 0.8516\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 946us/step - loss: 0.3299 - accuracy: 0.8586 - val_loss: 0.3581 - val_accuracy: 0.8493\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 0s 923us/step - loss: 0.3218 - accuracy: 0.8662 - val_loss: 0.3580 - val_accuracy: 0.8535\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 955us/step - loss: 0.3299 - accuracy: 0.8633 - val_loss: 0.3590 - val_accuracy: 0.8489\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 940us/step - loss: 0.3344 - accuracy: 0.8592 - val_loss: 0.3574 - val_accuracy: 0.8512\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3144 - accuracy: 0.8681 - val_loss: 0.3579 - val_accuracy: 0.8504\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 996us/step - loss: 0.3201 - accuracy: 0.8715 - val_loss: 0.3584 - val_accuracy: 0.8512\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 0s 913us/step - loss: 0.3306 - accuracy: 0.8675 - val_loss: 0.3581 - val_accuracy: 0.8512\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 0s 918us/step - loss: 0.3074 - accuracy: 0.8719 - val_loss: 0.3568 - val_accuracy: 0.8535\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 939us/step - loss: 0.3286 - accuracy: 0.8606 - val_loss: 0.3578 - val_accuracy: 0.8516\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 936us/step - loss: 0.3384 - accuracy: 0.8620 - val_loss: 0.3585 - val_accuracy: 0.8497\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 0s 919us/step - loss: 0.3222 - accuracy: 0.8641 - val_loss: 0.3571 - val_accuracy: 0.8497\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 1s 962us/step - loss: 0.3209 - accuracy: 0.8676 - val_loss: 0.3576 - val_accuracy: 0.8527\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 966us/step - loss: 0.3188 - accuracy: 0.8679 - val_loss: 0.3584 - val_accuracy: 0.8497\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 0s 920us/step - loss: 0.3307 - accuracy: 0.8612 - val_loss: 0.3569 - val_accuracy: 0.8546\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 958us/step - loss: 0.3469 - accuracy: 0.8571 - val_loss: 0.3571 - val_accuracy: 0.8508\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 1s 945us/step - loss: 0.3324 - accuracy: 0.8675 - val_loss: 0.3561 - val_accuracy: 0.8538\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 948us/step - loss: 0.3339 - accuracy: 0.8594 - val_loss: 0.3576 - val_accuracy: 0.8531\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 0s 914us/step - loss: 0.3212 - accuracy: 0.8697 - val_loss: 0.3566 - val_accuracy: 0.8512\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 936us/step - loss: 0.3322 - accuracy: 0.8622 - val_loss: 0.3573 - val_accuracy: 0.8561\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 1s 942us/step - loss: 0.3320 - accuracy: 0.8577 - val_loss: 0.3561 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 0s 915us/step - loss: 0.3393 - accuracy: 0.8594 - val_loss: 0.3558 - val_accuracy: 0.8519\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 0s 926us/step - loss: 0.3255 - accuracy: 0.8681 - val_loss: 0.3559 - val_accuracy: 0.8519\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 951us/step - loss: 0.3404 - accuracy: 0.8626 - val_loss: 0.3563 - val_accuracy: 0.8546\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 948us/step - loss: 0.3377 - accuracy: 0.8554 - val_loss: 0.3555 - val_accuracy: 0.8561\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 950us/step - loss: 0.3326 - accuracy: 0.8635 - val_loss: 0.3563 - val_accuracy: 0.8512\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 954us/step - loss: 0.3319 - accuracy: 0.8630 - val_loss: 0.3559 - val_accuracy: 0.8538\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 0s 927us/step - loss: 0.3227 - accuracy: 0.8641 - val_loss: 0.3551 - val_accuracy: 0.8565\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 1s 942us/step - loss: 0.3234 - accuracy: 0.8682 - val_loss: 0.3550 - val_accuracy: 0.8554\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3192 - accuracy: 0.8680 - val_loss: 0.3557 - val_accuracy: 0.8569\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 995us/step - loss: 0.3202 - accuracy: 0.8637 - val_loss: 0.3562 - val_accuracy: 0.8535\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 1s 953us/step - loss: 0.3222 - accuracy: 0.8663 - val_loss: 0.3546 - val_accuracy: 0.8565\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 0s 929us/step - loss: 0.3275 - accuracy: 0.8669 - val_loss: 0.3550 - val_accuracy: 0.8527\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 1s 962us/step - loss: 0.3250 - accuracy: 0.8673 - val_loss: 0.3551 - val_accuracy: 0.8523\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 0s 930us/step - loss: 0.3290 - accuracy: 0.8630 - val_loss: 0.3552 - val_accuracy: 0.8557\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 951us/step - loss: 0.3314 - accuracy: 0.8608 - val_loss: 0.3556 - val_accuracy: 0.8554\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 946us/step - loss: 0.3062 - accuracy: 0.8727 - val_loss: 0.3561 - val_accuracy: 0.8565\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 953us/step - loss: 0.3304 - accuracy: 0.8680 - val_loss: 0.3553 - val_accuracy: 0.8550\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 944us/step - loss: 0.3377 - accuracy: 0.8564 - val_loss: 0.3544 - val_accuracy: 0.8538\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 938us/step - loss: 0.3166 - accuracy: 0.8675 - val_loss: 0.3556 - val_accuracy: 0.8573\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 963us/step - loss: 0.3097 - accuracy: 0.8763 - val_loss: 0.3544 - val_accuracy: 0.8538\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 964us/step - loss: 0.3477 - accuracy: 0.8573 - val_loss: 0.3546 - val_accuracy: 0.8546\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 973us/step - loss: 0.3283 - accuracy: 0.8639 - val_loss: 0.3540 - val_accuracy: 0.8523\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 948us/step - loss: 0.3279 - accuracy: 0.8696 - val_loss: 0.3546 - val_accuracy: 0.8557\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 937us/step - loss: 0.3114 - accuracy: 0.8680 - val_loss: 0.3562 - val_accuracy: 0.8546\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 957us/step - loss: 0.3258 - accuracy: 0.8715 - val_loss: 0.3563 - val_accuracy: 0.8557\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 1s 935us/step - loss: 0.3091 - accuracy: 0.8719 - val_loss: 0.3542 - val_accuracy: 0.8535\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 0s 928us/step - loss: 0.3194 - accuracy: 0.8646 - val_loss: 0.3547 - val_accuracy: 0.8550\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 958us/step - loss: 0.3250 - accuracy: 0.8648 - val_loss: 0.3555 - val_accuracy: 0.8550\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 1s 959us/step - loss: 0.3269 - accuracy: 0.8668 - val_loss: 0.3550 - val_accuracy: 0.8554\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 942us/step - loss: 0.3268 - accuracy: 0.8678 - val_loss: 0.3537 - val_accuracy: 0.8542\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 965us/step - loss: 0.3387 - accuracy: 0.8624 - val_loss: 0.3564 - val_accuracy: 0.8516\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 967us/step - loss: 0.3295 - accuracy: 0.8626 - val_loss: 0.3537 - val_accuracy: 0.8542\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size = 10,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "#checking all data\n",
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data visualize\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1504,   91],\n",
       "       [ 193,  212]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Represting this with confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM = confusion_matrix(y_test,y_pred)\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the acc\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
